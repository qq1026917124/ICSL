---
run_name: YOUR_NAME_TO_RUN
master_port: "12402"
load_model_path: [Path or None]

log_config:
  use_tensorboard: True
  tensorboard_log: ./runs/
  training_log: ./runs/train.log
  evaluation_log: ./runs/eval.log

model_config:
  context_warmup: 1000
  max_position_loss_weighting: 32000
  vae_latent_size: 1024
  action_dim: 16
  policy_loss_type: CrossEntropy
  
  image_encoder_block:
      img_size: 128
      hidden_size: 1024
      n_res_block: 2

  image_decoder_block:
      input_size: 1024
      hidden_size: 1024
      img_size: 128
      n_res_block: 2

  decision_block:
      rsa_type: podaw  #potar, otar, oar, oa
      is_generate: False
      state_encode:
          input_type: Continuous
          input_size: 1024
          hidden_size: 1024
          dropout: 0.0

      action_encode:
          input_type: Discrete
          input_size: 17
          hidden_size: 1024
          dropout: 0.0

      prompt_encode:
          input_type: Continuous
          input_size: 768
          hidden_size: 1024
          dropout: 0.0
          is_frozen: False

      tag_encode:
          input_type: Discrete
          input_size: 8
          hidden_size: 1024
          dropout: 0.0
          is_frozen: False

      state_decode:
          output_type: Continuous
          input_size: 1024
          hidden_size:
              - 1024
              - 1024
          layer_norm: True
          residual_connect: True
          dropout: 0.0

      action_decode:
          output_type: Discrete
          input_size: 1024
          hidden_size:
              - 1024
              - 17
          layer_norm: True
          residual_connect: True
          dropout: 0.0
          
          
      action_diffusion:
          enable: False
          prediction_type: "sample" # epslion / sample /velocity
          diffusion_model_name: "latentlm" # latentlm / basic
          basic_model:
            hidden_size: 1024
            condition_size: 1024
            t_embedding_size: 32
            inner_hidden_size: 4096
            cond_layer_norm: True
            dropout: 0.1
          latentlm:
            hidden_size: 1024
            block_size: 3
            mlp_ratio: 4
            dropout: 0.0
          schedule: "cosine" # linear / cosine / scaled_linear
          T: 20
          beta: [0.0001, 0.02] # For linear / scaled_linear
          inference_sample_steps: 20
          eta: 1.0
          need_clip: False # Set True if predict type is epslion or velocity
          clip_threshold: 5.0
  
      state_diffusion:
          enable: False
          prediction_type: "sample" # epslion / sample / velocity
          diffusion_model_name: "latentlm" # latentlm / basic
          basic_model:
            hidden_size: 1024
            condition_size: 1024
            t_embedding_size: 32
            inner_hidden_size: 4096
            cond_layer_norm: True
            dropout: 0.1
          latentlm:
            hidden_size: 1024
            block_size: 5
            mlp_ratio: 6
            dropout: 0.0
          schedule: "cosine" # linear / cosine / scaled_linear
          T: 20
          beta: [0.0001, 0.02] # For linear / scaled_linear
          inference_sample_steps: 20
          eta: 1.0
          need_clip: False # Set True if predict type is epslion or velocity
          clip_threshold: 5.0

      causal_block_trans:
          model_type: TRANSFORMER
          num_layers: 18
          hidden_size: 1024
          nhead: 32
          inner_hidden_size: 1024
          dropout: 0.10
          context_window: -1
          checkpoints_density: -1
          position_encoding_size: 2048
          use_layer_norm: True
          use_blockrecurrence: True
          memory_length: 1024
          memory_type: KV
          
          
      causal_block:
          is_generate: False
          model_type: GSA # GLA
          num_layers: 18
          hidden_size: 1024
          inner_hidden_size: 1024
          dropout: 0.10
          nhead: 32
          memory_length: 64
          position_encoding_size: 2048
          use_layer_norm: True
          gate_bound: 22
          use_blockrecurrence: True
          checkpoints_density: -1
          memory_type: MEM



generator_config:

    in_context_len: 5000 # Length of in context learn
    pred_len: 1 # autoregressive length
    start_position: 0 # start position
    end_position: 2000 # end position
    max_maze: 16
    model_name: "DecoderColdPM" # "DecoderColdPM" / "DecoderWarmPM"
    record_interval: 1
    temp: 0.1 
    drop_out: 0.2
    output_root: "path/to/output" # output path
    data_path: "path/to/maze_data" # maze data path
    
    seq_len_causal: 5000
    max_trails: 1
    max_total_steps: 5000
    agent_num: 1
    epoch_numbers: 1